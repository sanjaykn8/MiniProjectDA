{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7eeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, ttk\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from math import log2\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57569ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_apriori_fp_growth():\n",
    "    # Create a new window (Toplevel) for displaying plots\n",
    "    window = tk.Toplevel()\n",
    "    window.title(\"Apriori & FP-Growth Visualizations\")\n",
    "    window.geometry(\"800x600\")\n",
    "    \n",
    "    # Create a Notebook (tabbed interface)\n",
    "    notebook = ttk.Notebook(window)\n",
    "    notebook.pack(fill='both', expand=True)\n",
    "\n",
    "    # --- Load Dataset ---\n",
    "    dataset_path = \"EPL.csv\"  # Adjust the path if needed\n",
    "    transactions = []\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            transactions.append(line.strip().split(','))\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    # --- Define Functions for Association Rule Mining ---\n",
    "    def get_association_rules(min_support, min_confidence, min_lift, min_length):\n",
    "        frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "        rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
    "        rules = rules[(rules['confidence'] >= min_confidence) &\n",
    "                      (rules['lift'] >= min_lift) &\n",
    "                      (rules['antecedents'].apply(lambda x: len(x) >= min_length - 1)) &\n",
    "                      (rules['consequents'].apply(lambda x: len(x) >= 1))]\n",
    "        return rules\n",
    "\n",
    "    def get_fp_growth_rules(df, min_support, min_confidence, min_lift, min_length):\n",
    "        frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
    "        rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
    "        rules = rules[(rules['confidence'] >= min_confidence) &\n",
    "                      (rules['lift'] >= min_lift) &\n",
    "                      (rules['antecedents'].apply(lambda x: len(x) >= min_length - 1)) &\n",
    "                      (rules['consequents'].apply(lambda x: len(x) >= 1))]\n",
    "        rules = rules.sort_values(by=['lift', 'confidence'], ascending=False)\n",
    "        return rules\n",
    "\n",
    "    # --- Generate Rules for Apriori ---\n",
    "    rules1 = get_association_rules(min_support=0.1, min_confidence=0.1, min_lift=2, min_length=2)\n",
    "    rules2 = get_association_rules(min_support=0.12, min_confidence=0.12, min_lift=2, min_length=2)\n",
    "\n",
    "    # --- Tab 1: Scatter Plot (Apriori Association Rules) ---\n",
    "    tab1 = ttk.Frame(notebook)\n",
    "    notebook.add(tab1, text=\"Apriori Scatter\")\n",
    "    fig1 = plt.Figure(figsize=(6, 4), dpi=100)\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    sc1 = ax1.scatter(rules1['support'], rules1['confidence'], c=rules1['lift'], cmap='coolwarm')\n",
    "    fig1.colorbar(sc1, ax=ax1, label=\"Lift\")\n",
    "    ax1.set_xlabel(\"Support\")\n",
    "    ax1.set_ylabel(\"Confidence\")\n",
    "    ax1.set_title(\"Scatter Plot of Apriori Association Rules\")\n",
    "    canvas1 = FigureCanvasTkAgg(fig1, master=tab1)\n",
    "    canvas1.draw()\n",
    "    canvas1.get_tk_widget().pack(fill='both', expand=True)\n",
    "\n",
    "    # --- Tab 2: Association Rules Graph ---\n",
    "    tab2 = ttk.Frame(notebook)\n",
    "    notebook.add(tab2, text=\"Association Graph\")\n",
    "    fig2 = plt.Figure(figsize=(6, 4), dpi=100)\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    G = nx.DiGraph()\n",
    "    # Use top 10 rules from rules2 for the graph\n",
    "    for _, rule in rules2.head(10).iterrows():\n",
    "        for antecedent in rule['antecedents']:\n",
    "            for consequent in rule['consequents']:\n",
    "                G.add_edge(antecedent, consequent, weight=rule['lift'])\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    nx.draw(G, pos, ax=ax2, edge_color='gray', node_color='lightblue', with_labels=True, font_size=8)\n",
    "    edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(G, pos, ax=ax2, edge_labels=edge_labels)\n",
    "    ax2.set_title(\"Graph of Association Rules\")\n",
    "    canvas2 = FigureCanvasTkAgg(fig2, master=tab2)\n",
    "    canvas2.draw()\n",
    "    canvas2.get_tk_widget().pack(fill='both', expand=True)\n",
    "\n",
    "    # --- Tab 3: Scatter Plot (FP-Growth Association Rules) ---\n",
    "    tab3 = ttk.Frame(notebook)\n",
    "    notebook.add(tab3, text=\"FP-Growth Scatter\")\n",
    "    rules1_fp = get_fp_growth_rules(df, min_support=0.1, min_confidence=0.1, min_lift=2, min_length=2)\n",
    "    rules2_fp = get_fp_growth_rules(df, min_support=0.12, min_confidence=0.12, min_lift=2, min_length=2)\n",
    "    fig3 = plt.Figure(figsize=(6, 4), dpi=100)\n",
    "    ax3 = fig3.add_subplot(111)\n",
    "    sc3 = ax3.scatter(rules1_fp['support'], rules1_fp['confidence'], c=rules1_fp['lift'], cmap='coolwarm')\n",
    "    fig3.colorbar(sc3, ax=ax3, label=\"Lift\")\n",
    "    ax3.set_xlabel(\"Support\")\n",
    "    ax3.set_ylabel(\"Confidence\")\n",
    "    ax3.set_title(\"Scatter Plot of FP-Growth Association Rules\")\n",
    "    canvas3 = FigureCanvasTkAgg(fig3, master=tab3)\n",
    "    canvas3.draw()\n",
    "    canvas3.get_tk_widget().pack(fill='both', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37de698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bayes():\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('EPL.csv')\n",
    "    df = df.drop(columns=[\"MatchID\", \"Date\", \"Time\", \"Referee\"])\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\":\n",
    "            df[column] = df[column].fillna(df[column].mode()[0])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].median())  \n",
    "\n",
    "    categorical_columns = [\"Season\", \"HomeTeam\", \"AwayTeam\", \"FullTimeResult\", \"HalfTimeResult\"]\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    X = df.drop(columns=[\"FullTimeResult\"])  \n",
    "    y = df[\"FullTimeResult\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # --- Window for Confusion Matrix ---\n",
    "    cm_window = tk.Toplevel()\n",
    "    cm_window.title(\"Confusion Matrix - Naïve Bayes\")\n",
    "    cm_window.geometry(\"700x500\")\n",
    "    \n",
    "    fig_cm = plt.Figure(figsize=(6, 4), dpi=100)\n",
    "    ax_cm = fig_cm.add_subplot(111)\n",
    "    heatmap = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                          xticklabels=label_encoders[\"FullTimeResult\"].classes_, \n",
    "                          yticklabels=label_encoders[\"FullTimeResult\"].classes_,\n",
    "                          ax=ax_cm)\n",
    "    ax_cm.set_xlabel(\"Predicted Label\")\n",
    "    ax_cm.set_ylabel(\"True Label\")\n",
    "    ax_cm.set_title(\"Confusion Matrix - Naïve Bayes\")\n",
    "    \n",
    "    canvas_cm = FigureCanvasTkAgg(fig_cm, master=cm_window)\n",
    "    canvas_cm.draw()\n",
    "    canvas_cm.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # --- Window for Metrics ---\n",
    "    metrics_window = tk.Toplevel()\n",
    "    metrics_window.title(\"Naïve Bayes Metrics\")\n",
    "    metrics_window.geometry(\"400x250\")\n",
    "    \n",
    "    # Create a frame to hold the labels\n",
    "    frame = ttk.Frame(metrics_window, padding=20)\n",
    "    frame.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # Create and grid labels for the scores\n",
    "    ttk.Label(frame, text=f\"Accuracy: {accuracy:.4f}\", font=(\"Arial\", 12)).grid(row=0, column=0, sticky=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"Precision: {precision:.4f}\", font=(\"Arial\", 12)).grid(row=1, column=0, sticky=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"Recall: {recall:.4f}\", font=(\"Arial\", 12)).grid(row=2, column=0, sticky=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"F1 Score: {f1:.4f}\", font=(\"Arial\", 12)).grid(row=3, column=0, sticky=\"w\", pady=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3246276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_id3():\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('EPL.csv')\n",
    "    df = df[['HomeTeam', 'AwayTeam', 'FullTimeResult', 'HalfTimeResult']]\n",
    "    df = df.apply(lambda x: pd.factorize(x)[0])\n",
    "    \n",
    "    # Helper functions for entropy and information gain\n",
    "    def entropy(data):\n",
    "        total = len(data)\n",
    "        counts = Counter(data)\n",
    "        return -sum((count/total) * log2(count/total) for count in counts.values())\n",
    "    \n",
    "    def information_gain(df, feature, target):\n",
    "        total_entropy = entropy(df[target])\n",
    "        values = df[feature].unique()\n",
    "        weighted_entropy = sum(\n",
    "            (len(df[df[feature] == v]) / len(df)) * entropy(df[df[feature] == v][target])\n",
    "            for v in values\n",
    "        )\n",
    "        return total_entropy - weighted_entropy\n",
    "    \n",
    "    # Calculate information gain for each feature\n",
    "    info_gains = {feature: information_gain(df, feature, 'FullTimeResult') for feature in df.columns[:-1]}\n",
    "    best_feature = max(info_gains, key=info_gains.get)\n",
    "    print(\"\\nInformation Gain for Each Feature:\")\n",
    "    for feature, gain in info_gains.items():\n",
    "        print(f\"{feature}: {gain:.4f}\")\n",
    "    print(f\"\\nBest Feature for Splitting: {best_feature}\")\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = df.drop(columns=['FullTimeResult'])\n",
    "    y = df['FullTimeResult']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Train the Decision Tree (ID3)\n",
    "    tree_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, \n",
    "                                          min_samples_split=10, min_samples_leaf=5)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    \n",
    "    # --- Create new window for Decision Tree plot ---\n",
    "    tree_window = tk.Toplevel()\n",
    "    tree_window.title(\"ID3 Decision Tree\")\n",
    "    tree_window.geometry(\"800x600\")\n",
    "    \n",
    "    fig_tree = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_tree = fig_tree.add_subplot(111)\n",
    "    plot_tree(tree_model, feature_names=X.columns, class_names=['H', 'D', 'A'], \n",
    "              filled=True, ax=ax_tree)\n",
    "    \n",
    "    canvas_tree = FigureCanvasTkAgg(fig_tree, master=tree_window)\n",
    "    canvas_tree.draw()\n",
    "    canvas_tree.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # Calculate feature importances (optional)\n",
    "    importances = tree_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # Predict and compute metrics\n",
    "    y_pred = tree_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # --- Create new window for Metrics display ---\n",
    "    metrics_window = tk.Toplevel()\n",
    "    metrics_window.title(\"ID3 Metrics\")\n",
    "    metrics_window.geometry(\"400x300\")\n",
    "    \n",
    "    frame = ttk.Frame(metrics_window, padding=20)\n",
    "    frame.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    ttk.Label(frame, text=f\"Accuracy: {accuracy:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"Precision: {precision:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"Recall: {recall:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"F1 Score: {f1:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "089fbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cart():\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('EPL.csv')\n",
    "    df = df[['HomeTeam', 'AwayTeam', 'FullTimeResult', 'HalfTimeResult']]\n",
    "    df = df.apply(lambda x: pd.factorize(x)[0])\n",
    "    \n",
    "    # Define entropy function\n",
    "    def entropy(data):\n",
    "        total = len(data)\n",
    "        counts = Counter(data)\n",
    "        return -sum((count/total) * log2(count/total) for count in counts.values())\n",
    "    \n",
    "    target_entropy = entropy(df['HalfTimeResult'])\n",
    "    \n",
    "    # Define information gain function\n",
    "    def information_gain(df, feature, target):\n",
    "        total_entropy = entropy(df[target])\n",
    "        values = df[feature].unique()\n",
    "        weighted_entropy = sum(\n",
    "            (len(df[df[feature] == v]) / len(df)) * entropy(df[df[feature] == v][target])\n",
    "            for v in values\n",
    "        )\n",
    "        return total_entropy - weighted_entropy\n",
    "    \n",
    "    info_gains = {feature: information_gain(df, feature, 'FullTimeResult') for feature in df.columns[:-1]}\n",
    "    best_feature = max(info_gains, key=info_gains.get)\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = df.drop(columns=['FullTimeResult'])\n",
    "    y = df['FullTimeResult']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Initialize and fit the CART model (using Gini impurity)\n",
    "    cart_tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, \n",
    "                                         min_samples_split=10, min_samples_leaf=5)\n",
    "    cart_tree.fit(X_train, y_train)\n",
    "    \n",
    "    # --- Window 1: CART Decision Tree Plot ---\n",
    "    tree_window = tk.Toplevel()\n",
    "    tree_window.title(\"CART Decision Tree\")\n",
    "    tree_window.geometry(\"800x600\")\n",
    "    \n",
    "    fig_tree = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_tree = fig_tree.add_subplot(111)\n",
    "    plot_tree(cart_tree, feature_names=X.columns, class_names=['H', 'D', 'A'],\n",
    "              filled=True, ax=ax_tree)\n",
    "    \n",
    "    canvas_tree = FigureCanvasTkAgg(fig_tree, master=tree_window)\n",
    "    canvas_tree.draw()\n",
    "    canvas_tree.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # --- Window 2: Metrics Display ---\n",
    "    y_pred = cart_tree.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    metrics_window = tk.Toplevel()\n",
    "    metrics_window.title(\"CART Metrics\")\n",
    "    metrics_window.geometry(\"400x300\")\n",
    "    \n",
    "    frame_metrics = ttk.Frame(metrics_window, padding=20)\n",
    "    frame_metrics.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    ttk.Label(frame_metrics, text=f\"Accuracy: {accuracy:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame_metrics, text=f\"Precision: {precision:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame_metrics, text=f\"Recall: {recall:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame_metrics, text=f\"F1 Score: {f1:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    \n",
    "    # --- Window 3: Correlation Heatmap ---\n",
    "    corr_matrix = df.corr()\n",
    "    \n",
    "    heatmap_window = tk.Toplevel()\n",
    "    heatmap_window.title(\"Feature Correlation Heatmap\")\n",
    "    heatmap_window.geometry(\"800x600\")\n",
    "    \n",
    "    fig_heat = plt.Figure(figsize=(10, 8), dpi=100)\n",
    "    ax_heat = fig_heat.add_subplot(111)\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5, ax=ax_heat)\n",
    "    ax_heat.set_title(\"Feature Correlation Heatmap\")\n",
    "    \n",
    "    canvas_heat = FigureCanvasTkAgg(fig_heat, master=heatmap_window)\n",
    "    canvas_heat.draw()\n",
    "    canvas_heat.get_tk_widget().pack(fill=\"both\", expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91ba431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_c45():\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('EPL.csv')\n",
    "    df = df[['HomeTeam', 'AwayTeam', 'FullTimeResult', 'HalfTimeResult']]\n",
    "    df = df.apply(lambda x: pd.factorize(x)[0])\n",
    "    \n",
    "    # Define entropy function\n",
    "    def entropy(data):\n",
    "        total = len(data)\n",
    "        counts = Counter(data)\n",
    "        return -sum((count/total) * log2(count/total) for count in counts.values())\n",
    "    \n",
    "    target_entropy = entropy(df['HalfTimeResult'])\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = df.drop(columns=['FullTimeResult'])\n",
    "    y = df['FullTimeResult']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Initialize and fit the C4.5 model (using entropy)\n",
    "    c45_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, \n",
    "                                      min_samples_split=10, min_samples_leaf=5)\n",
    "    c45_tree.fit(X_train, y_train)\n",
    "    \n",
    "    # --- Window 1: Decision Tree Plot ---\n",
    "    tree_window = tk.Toplevel()\n",
    "    tree_window.title(\"C4.5 Decision Tree\")\n",
    "    tree_window.geometry(\"800x600\")\n",
    "    \n",
    "    fig_tree = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_tree = fig_tree.add_subplot(111)\n",
    "    plot_tree(c45_tree, feature_names=X.columns, class_names=['H', 'D', 'A'], \n",
    "              filled=True, ax=ax_tree)\n",
    "    \n",
    "    canvas_tree = FigureCanvasTkAgg(fig_tree, master=tree_window)\n",
    "    canvas_tree.draw()\n",
    "    canvas_tree.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # --- Window 2: Metrics Display ---\n",
    "    y_pred = c45_tree.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    metrics_window = tk.Toplevel()\n",
    "    metrics_window.title(\"C4.5 Metrics\")\n",
    "    metrics_window.geometry(\"400x300\")\n",
    "    \n",
    "    frame = ttk.Frame(metrics_window, padding=20)\n",
    "    frame.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    ttk.Label(frame, text=f\"Accuracy: {accuracy:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"Precision: {precision:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"Recall: {recall:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n",
    "    ttk.Label(frame, text=f\"F1 Score: {f1:.4f}\", font=(\"Arial\", 12)).pack(anchor=\"w\", pady=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036066d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_knn():\n",
    "    # Load data and define features/target\n",
    "    df = pd.read_csv(\"EPL.csv\") \n",
    "    features = [\n",
    "        \"HomeTeamShots\", \"AwayTeamShots\", \"HomeTeamShotsOnTarget\", \"AwayTeamShotsOnTarget\",\n",
    "        \"HomeTeamCorners\", \"AwayTeamCorners\", \"HomeTeamFouls\", \"AwayTeamFouls\",\n",
    "        \"HomeTeamYellowCards\", \"AwayTeamYellowCards\", \"B365HomeTeam\", \"B365Draw\", \"B365AwayTeam\"\n",
    "    ]\n",
    "    target = \"FullTimeResult\"\n",
    "    \n",
    "    # Encode target labels\n",
    "    le = LabelEncoder()\n",
    "    df[target] = le.fit_transform(df[target])\n",
    "    df.dropna(subset=features + [target], inplace=True)\n",
    "\n",
    "    # Prepare features and labels\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train KNN with k=100\n",
    "    k = 100\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Compute metrics and report\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # --- Window 1: Classification Report --- \n",
    "    report_window = tk.Toplevel()\n",
    "    report_window.title(\"KNN Classification Report\")\n",
    "    report_window.geometry(\"500x400\")\n",
    "    \n",
    "    # Create a frame and a Text widget to display the report\n",
    "    frame_report = ttk.Frame(report_window, padding=10)\n",
    "    frame_report.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    report_text = tk.Text(frame_report, wrap=\"word\", font=(\"Consolas\", 10))\n",
    "    report_text.insert(\"1.0\", f\"Accuracy: {accuracy:.4f}\\n\\n{report}\")\n",
    "    report_text.config(state=\"disabled\")  # Make the text widget read-only\n",
    "    report_text.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # --- Window 2: Confusion Matrix Plot ---\n",
    "    cm_window = tk.Toplevel()\n",
    "    cm_window.title(\"KNN Confusion Matrix\")\n",
    "    cm_window.geometry(\"600x500\")\n",
    "    \n",
    "    fig_cm = plt.Figure(figsize=(6, 4), dpi=100)\n",
    "    ax_cm = fig_cm.add_subplot(111)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_, ax=ax_cm)\n",
    "    ax_cm.set_xlabel(\"Predicted Label\")\n",
    "    ax_cm.set_ylabel(\"True Label\")\n",
    "    ax_cm.set_title(\"Confusion Matrix\")\n",
    "    \n",
    "    canvas_cm = FigureCanvasTkAgg(fig_cm, master=cm_window)\n",
    "    canvas_cm.draw()\n",
    "    canvas_cm.get_tk_widget().pack(fill=\"both\", expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8291eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kmeans():\n",
    "    # Load data and fill missing numeric values\n",
    "    df = pd.read_csv(\"EPL.csv\")\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Create new features\n",
    "    df[\"TotalGoals\"] = df[\"FullTimeHomeTeamGoals\"] + df[\"FullTimeAwayTeamGoals\"]\n",
    "    df[\"GoalDifference\"] = df[\"FullTimeHomeTeamGoals\"] - df[\"FullTimeAwayTeamGoals\"]\n",
    "    df[\"WinRate\"] = df[\"HomeTeamPoints\"] / (df[\"HomeTeamPoints\"] + df[\"AwayTeamPoints\"])\n",
    "\n",
    "    # Scale features for clustering\n",
    "    features = df[[\"TotalGoals\", \"GoalDifference\", \"WinRate\"]]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Compute inertia for a range of k values (Elbow Method)\n",
    "    inertia = []\n",
    "    K_range = range(1, 11)\n",
    "    for k in K_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(scaled_features)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # --- Window 1: Elbow Method Plot ---\n",
    "    elbow_window = tk.Toplevel()\n",
    "    elbow_window.title(\"Elbow Method for Optimal K\")\n",
    "    elbow_window.geometry(\"800x600\")\n",
    "    \n",
    "    fig_elbow = plt.Figure(figsize=(8, 6), dpi=100)\n",
    "    ax_elbow = fig_elbow.add_subplot(111)\n",
    "    ax_elbow.plot(K_range, inertia, marker='o')\n",
    "    ax_elbow.set_xlabel('Number of Clusters (K)')\n",
    "    ax_elbow.set_ylabel('Inertia')\n",
    "    ax_elbow.set_title('Elbow Method for Optimal K')\n",
    "    \n",
    "    canvas_elbow = FigureCanvasTkAgg(fig_elbow, master=elbow_window)\n",
    "    canvas_elbow.draw()\n",
    "    canvas_elbow.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # --- K-Means Clustering ---\n",
    "    # For this example, we set optimal_k to 10 (you can compute or adjust as needed)\n",
    "    optimal_k = 10\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    df[\"Cluster\"] = kmeans.fit_predict(scaled_features)\n",
    "    \n",
    "    # Compute silhouette score if there is more than one cluster\n",
    "    silhouette_avg = None\n",
    "    if len(set(df[\"Cluster\"])) > 1:\n",
    "        silhouette_avg = silhouette_score(scaled_features, df[\"Cluster\"])\n",
    "    \n",
    "    # --- Window 2: Clustering Scatter Plot ---\n",
    "    scatter_window = tk.Toplevel()\n",
    "    title = \"K-Means Clustering of EPL Teams\"\n",
    "    if silhouette_avg is not None:\n",
    "        title += f\" (Silhouette Score: {silhouette_avg:.4f})\"\n",
    "    scatter_window.title(title)\n",
    "    scatter_window.geometry(\"900x600\")\n",
    "    \n",
    "    fig_scatter = plt.Figure(figsize=(9, 6), dpi=100)\n",
    "    ax_scatter = fig_scatter.add_subplot(111)\n",
    "    sc = ax_scatter.scatter(df[\"TotalGoals\"], df[\"WinRate\"], c=df[\"Cluster\"], cmap=\"viridis\", edgecolors='k')\n",
    "    ax_scatter.set_xlabel(\"Total Goals\")\n",
    "    ax_scatter.set_ylabel(\"Win Rate\")\n",
    "    ax_scatter.set_title(\"K-Means Clustering of EPL Teams\")\n",
    "    fig_scatter.colorbar(sc, ax=ax_scatter, label=\"Cluster\")\n",
    "    \n",
    "    canvas_scatter = FigureCanvasTkAgg(fig_scatter, master=scatter_window)\n",
    "    canvas_scatter.draw()\n",
    "    canvas_scatter.get_tk_widget().pack(fill=\"both\", expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4cbd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_agglomerative():\n",
    "    # Step 1: Load and process data\n",
    "    df = pd.read_csv(\"EPL.csv\")\n",
    "    df[\"TotalGoals\"] = df[\"FullTimeHomeTeamGoals\"] + df[\"FullTimeAwayTeamGoals\"]\n",
    "    df[\"GoalDifference\"] = df[\"FullTimeHomeTeamGoals\"] - df[\"FullTimeAwayTeamGoals\"]\n",
    "    df[\"WinRate\"] = df[\"HomeTeamPoints\"] / (df[\"HomeTeamPoints\"] + df[\"AwayTeamPoints\"])\n",
    "\n",
    "    features = df[[\"TotalGoals\", \"GoalDifference\", \"WinRate\"]]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Step 2: Tkinter window for Dendrogram\n",
    "    dendro_window = tk.Toplevel()\n",
    "    dendro_window.title(\"Dendrogram - Agglomerative Clustering\")\n",
    "    dendro_window.geometry(\"1000x700\")\n",
    "\n",
    "    fig_dendro = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_dendro = fig_dendro.add_subplot(111)\n",
    "    sch.dendrogram(sch.linkage(scaled_features, method='ward'), ax=ax_dendro)\n",
    "    ax_dendro.set_title('Dendrogram for Agglomerative Clustering')\n",
    "    ax_dendro.set_xlabel('Teams')\n",
    "    ax_dendro.set_ylabel('Euclidean Distance')\n",
    "\n",
    "    canvas_dendro = FigureCanvasTkAgg(fig_dendro, master=dendro_window)\n",
    "    canvas_dendro.draw()\n",
    "    canvas_dendro.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "\n",
    "    # Step 3: Apply Agglomerative Clustering\n",
    "    optimal_k = 6\n",
    "    agglo_cluster = AgglomerativeClustering(n_clusters=optimal_k, linkage='complete', metric='euclidean')\n",
    "    df[\"Cluster\"] = agglo_cluster.fit_predict(scaled_features)\n",
    "\n",
    "    # Step 4: Tkinter window for clustering scatter plot\n",
    "    cluster_window = tk.Toplevel()\n",
    "    silhouette_avg = None\n",
    "    if len(set(df[\"Cluster\"])) > 1:\n",
    "        silhouette_avg = silhouette_score(scaled_features, df[\"Cluster\"])\n",
    "\n",
    "    title = \"Agglomerative Clustering of EPL Teams\"\n",
    "    if silhouette_avg:\n",
    "        title += f\" (Silhouette Score: {silhouette_avg:.4f})\"\n",
    "    cluster_window.title(title)\n",
    "    cluster_window.geometry(\"1000x700\")\n",
    "\n",
    "    fig_scatter = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_scatter = fig_scatter.add_subplot(111)\n",
    "    sc = ax_scatter.scatter(df[\"TotalGoals\"], df[\"WinRate\"], c=df[\"Cluster\"], cmap=\"rainbow\", edgecolors='k')\n",
    "    ax_scatter.set_xlabel(\"Total Goals\")\n",
    "    ax_scatter.set_ylabel(\"Win Rate\")\n",
    "    ax_scatter.set_title(\"Agglomerative Clustering of EPL Teams\")\n",
    "    fig_scatter.colorbar(sc, ax=ax_scatter, label=\"Cluster\")\n",
    "\n",
    "    canvas_scatter = FigureCanvasTkAgg(fig_scatter, master=cluster_window)\n",
    "    canvas_scatter.draw()\n",
    "    canvas_scatter.get_tk_widget().pack(fill=\"both\", expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f8d296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dbscan():\n",
    "    # Step 1: Load and engineer features\n",
    "    df = pd.read_csv(\"EPL.csv\")\n",
    "    df[\"TotalGoals\"] = df[\"FullTimeHomeTeamGoals\"] + df[\"FullTimeAwayTeamGoals\"]\n",
    "    df[\"GoalDifference\"] = df[\"FullTimeHomeTeamGoals\"] - df[\"FullTimeAwayTeamGoals\"]\n",
    "    df[\"WinRate\"] = df[\"HomeTeamPoints\"] / (df[\"HomeTeamPoints\"] + df[\"AwayTeamPoints\"])\n",
    "\n",
    "    features = df[[\"TotalGoals\", \"GoalDifference\", \"WinRate\"]]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Step 2: K-distance graph to estimate epsilon\n",
    "    k = 10\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, metric='euclidean').fit(scaled_features)\n",
    "    distances, indices = nbrs.kneighbors(scaled_features)\n",
    "    distances = np.sort(distances[:, k - 1])  # 10th neighbor distance\n",
    "\n",
    "    # Tkinter window for K-distance graph\n",
    "    kd_window = tk.Toplevel()\n",
    "    kd_window.title(\"DBSCAN - K-Distance Graph\")\n",
    "    kd_window.geometry(\"1000x700\")\n",
    "\n",
    "    fig_kd = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_kd = fig_kd.add_subplot(111)\n",
    "    ax_kd.plot(distances)\n",
    "    ax_kd.set_xlabel('Data Points Sorted by Distance')\n",
    "    ax_kd.set_ylabel(f'{k}th Nearest Neighbor Distance')\n",
    "    ax_kd.set_title('K-Distance Graph to Determine Epsilon')\n",
    "\n",
    "    canvas_kd = FigureCanvasTkAgg(fig_kd, master=kd_window)\n",
    "    canvas_kd.draw()\n",
    "    canvas_kd.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "\n",
    "    # Step 3: Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5, metric='euclidean')\n",
    "    df[\"Cluster\"] = dbscan.fit_predict(scaled_features)\n",
    "\n",
    "    # Step 4: Tkinter window for clustering scatter plot\n",
    "    dbscan_window = tk.Toplevel()\n",
    "    silhouette_avg = None\n",
    "    if len(set(df[\"Cluster\"])) > 1 and -1 not in set(df[\"Cluster\"]):\n",
    "        silhouette_avg = silhouette_score(scaled_features, df[\"Cluster\"])\n",
    "\n",
    "    title = \"DBSCAN Clustering of EPL Teams\"\n",
    "    if silhouette_avg:\n",
    "        title += f\" (Silhouette Score: {silhouette_avg:.4f})\"\n",
    "    dbscan_window.title(title)\n",
    "    dbscan_window.geometry(\"1000x700\")\n",
    "\n",
    "    fig_scatter = plt.Figure(figsize=(10, 6), dpi=100)\n",
    "    ax_scatter = fig_scatter.add_subplot(111)\n",
    "    sc = ax_scatter.scatter(df[\"TotalGoals\"], df[\"WinRate\"], c=df[\"Cluster\"], cmap=\"rainbow\", edgecolors='k')\n",
    "    ax_scatter.set_xlabel(\"Total Goals\")\n",
    "    ax_scatter.set_ylabel(\"Win Rate\")\n",
    "    ax_scatter.set_title(\"DBSCAN Clustering of EPL Teams\")\n",
    "    fig_scatter.colorbar(sc, ax=ax_scatter, label=\"Cluster\")\n",
    "\n",
    "    canvas_scatter = FigureCanvasTkAgg(fig_scatter, master=dbscan_window)\n",
    "    canvas_scatter.draw()\n",
    "    canvas_scatter.get_tk_widget().pack(fill=\"both\", expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4cea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_final_prediction():\n",
    "    df = pd.read_csv('EPL.csv')\n",
    "    def predict():\n",
    "        def compute_team_stats(df):\n",
    "            team_stats = {}\n",
    "\n",
    "            for team in pd.unique(df[['HomeTeam', 'AwayTeam']].values.ravel('K')):\n",
    "                home_matches = df[df['HomeTeam'] == team]\n",
    "                away_matches = df[df['AwayTeam'] == team]\n",
    "\n",
    "                home_wins = (home_matches['FullTimeResult'] == 'H').sum()\n",
    "                away_wins = (away_matches['FullTimeResult'] == 'A').sum()\n",
    "                home_games = len(home_matches)\n",
    "                away_games = len(away_matches)\n",
    "\n",
    "                home_win_pct = home_wins / home_games if home_games > 0 else 0\n",
    "                away_win_pct = away_wins / away_games if away_games > 0 else 0\n",
    "\n",
    "                home_avg_goals = home_matches['FullTimeHomeTeamGoals'].mean() if home_games > 0 else 0\n",
    "                away_avg_goals = away_matches['FullTimeAwayTeamGoals'].mean() if away_games > 0 else 0\n",
    "                home_avg_shots = home_matches['HomeTeamShots'].mean() if home_games > 0 else 0\n",
    "                away_avg_shots = away_matches['AwayTeamShots'].mean() if away_games > 0 else 0\n",
    "\n",
    "                home_avg_shots_on_target = home_matches['HomeTeamShotsOnTarget'].mean() if home_games > 0 else 0\n",
    "                away_avg_shots_on_target = away_matches['AwayTeamShotsOnTarget'].mean() if away_games > 0 else 0\n",
    "                home_avg_fouls = home_matches['HomeTeamFouls'].mean() if home_games > 0 else 0\n",
    "                away_avg_fouls = away_matches['AwayTeamFouls'].mean() if away_games > 0 else 0\n",
    "\n",
    "                team_stats[team] = {\n",
    "                    'home_win_pct': home_win_pct,\n",
    "                    'away_win_pct': away_win_pct,\n",
    "                    'home_avg_goals': home_avg_goals,\n",
    "                    'away_avg_goals': away_avg_goals,\n",
    "                    'home_avg_shots': home_avg_shots,\n",
    "                    'away_avg_shots': away_avg_shots,\n",
    "                    'home_avg_shots_on_target': home_avg_shots_on_target,\n",
    "                    'away_avg_shots_on_target': away_avg_shots_on_target,\n",
    "                    'home_avg_fouls': home_avg_fouls,\n",
    "                    'away_avg_fouls': away_avg_fouls\n",
    "                }\n",
    "\n",
    "            return team_stats\n",
    "        \n",
    "        team_stats = compute_team_stats(df)\n",
    "\n",
    "        features = []\n",
    "        goal_labels = []\n",
    "        shot_labels = []\n",
    "        shot_on_target_labels = []\n",
    "        foul_labels = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            home_team = row['HomeTeam']\n",
    "            away_team = row['AwayTeam']\n",
    "\n",
    "            if home_team in team_stats and away_team in team_stats:\n",
    "                home = team_stats[home_team]\n",
    "                away = team_stats[away_team]\n",
    "\n",
    "                features.append([\n",
    "                    home['home_win_pct'], away['away_win_pct'],\n",
    "                    home['home_avg_goals'], away['away_avg_goals'],\n",
    "                    home['home_avg_shots'], away['away_avg_shots'],\n",
    "                    home['home_avg_shots_on_target'], away['away_avg_shots_on_target'],\n",
    "                    home['home_avg_fouls'], away['away_avg_fouls']\n",
    "                ])\n",
    "\n",
    "                goal_labels.append([row['FullTimeHomeTeamGoals'], row['FullTimeAwayTeamGoals']])  \n",
    "                shot_labels.append([row['HomeTeamShots'], row['AwayTeamShots']])\n",
    "                shot_on_target_labels.append([row['HomeTeamShotsOnTarget'], row['AwayTeamShotsOnTarget']])\n",
    "                foul_labels.append([row['HomeTeamFouls'], row['AwayTeamFouls']])\n",
    "                \n",
    "        X = np.array(features)\n",
    "        y_goals = np.array(goal_labels)\n",
    "        y_shots = np.array(shot_labels)\n",
    "        y_shots_on_target = np.array(shot_on_target_labels)\n",
    "        y_fouls = np.array(foul_labels)\n",
    "\n",
    "        X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X, y_goals, test_size=0.1, random_state=42)\n",
    "        X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X, y_shots, test_size=0.1, random_state=42)\n",
    "        X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(X, y_shots_on_target, test_size=0.1, random_state=42)\n",
    "        X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X, y_fouls, test_size=0.1, random_state=42)\n",
    "\n",
    "        goal_regressor = DecisionTreeRegressor(random_state=42)\n",
    "        goal_regressor.fit(X_train_g, y_train_g)\n",
    "\n",
    "        shot_regressor = DecisionTreeRegressor(random_state=42)\n",
    "        shot_regressor.fit(X_train_s, y_train_s)\n",
    "\n",
    "        shot_on_target_regressor = DecisionTreeRegressor(random_state=42)\n",
    "        shot_on_target_regressor.fit(X_train_st, y_train_st)\n",
    "\n",
    "        foul_regressor = DecisionTreeRegressor(random_state=42)\n",
    "        foul_regressor.fit(X_train_f, y_train_f)\n",
    "        \n",
    "        \n",
    "        def predict_match(home_team, away_team):\n",
    "            if home_team not in team_stats or away_team not in team_stats:\n",
    "                return \"Invalid teams!\"\n",
    "\n",
    "            home = team_stats[home_team]\n",
    "            away = team_stats[away_team]\n",
    "\n",
    "            input_features = np.array([[\n",
    "                home['home_win_pct'], away['away_win_pct'],\n",
    "                home['home_avg_goals'], away['away_avg_goals'],\n",
    "                home['home_avg_shots'], away['away_avg_shots'],\n",
    "                home['home_avg_shots_on_target'], away['away_avg_shots_on_target'],\n",
    "                home['home_avg_fouls'], away['away_avg_fouls']\n",
    "            ]]).reshape(1, -1)\n",
    "\n",
    "            goal_pred = goal_regressor.predict(input_features)[0]  \n",
    "            shot_pred = shot_regressor.predict(input_features)[0]\n",
    "            shot_on_target_pred = shot_on_target_regressor.predict(input_features)[0]\n",
    "            foul_pred = foul_regressor.predict(input_features)[0]\n",
    "\n",
    "            home_goals, away_goals = int(round(goal_pred[0])), int(round(goal_pred[1]))\n",
    "            home_shots, away_shots = int(round(shot_pred[0])), int(round(shot_pred[1]))\n",
    "            home_shots_on_target, away_shots_on_target = int(round(shot_on_target_pred[0])), int(round(shot_on_target_pred[1]))\n",
    "            home_fouls, away_fouls = int(round(foul_pred[0])), int(round(foul_pred[1]))\n",
    "\n",
    "            if home_goals > away_goals:\n",
    "                result_pred = \"H\"  \n",
    "            elif away_goals > home_goals:\n",
    "                result_pred = \"A\"  \n",
    "            else:\n",
    "                result_pred = \"D\"  \n",
    "\n",
    "            return f\"\"\"\n",
    "            Predicted Outcome: {result_pred}\n",
    "            Expected Full-Time Goals: {home_team} {home_goals} - {away_goals} {away_team}\n",
    "            Expected Shots: {home_team} {home_shots} - {away_shots} {away_team}\n",
    "            Expected Shots on Target: {home_team} {home_shots_on_target} - {away_shots_on_target} {away_team}\n",
    "            Expected Fouls: {home_team} {home_fouls} - {away_fouls} {away_team}\n",
    "            \"\"\"\n",
    "\n",
    "        \n",
    "        home_team = team1_entry.get()\n",
    "        away_team = team2_entry.get()\n",
    "        result = predict_match(home_team, away_team)\n",
    "        result_label.config(text=result)\n",
    "\n",
    "\n",
    "    input_window = tk.Toplevel()\n",
    "    input_window.title(\"Final Prediction Input\")\n",
    "    tk.Label(input_window, text=\"Team 1:\").grid(row=0, column=0, padx=5, pady=5)\n",
    "    team1_entry = tk.Entry(input_window)\n",
    "    team1_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "    tk.Label(input_window, text=\"Team 2:\").grid(row=1, column=0, padx=5, pady=5)\n",
    "    team2_entry = tk.Entry(input_window)\n",
    "    team2_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "    result_label = tk.Label(input_window, text=\"\", justify=\"left\", anchor=\"w\")\n",
    "    result_label.grid(row=3, column=0, columnspan=2, sticky=\"w\", padx=5, pady=5)\n",
    "    \n",
    "    tk.Button(input_window, text=\"Predict\", command=predict).grid(row=2, columnspan=2, pady=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_functions = {\n",
    "    \"Apriori & FP Growth\": visualize_apriori_fp_growth,\n",
    "    \"Bayes\": visualize_bayes,\n",
    "    \"ID3\": visualize_id3,\n",
    "    \"CART\": visualize_cart,\n",
    "    \"C4.5\": visualize_c45,\n",
    "    \"KNN\": visualize_knn,\n",
    "    \"K-Means\": visualize_kmeans,\n",
    "    \"Agglomerative\": visualize_agglomerative,\n",
    "    \"DBSCAN\": visualize_dbscan,\n",
    "    \"Final Prediction using 2 Teams\": visualize_final_prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f0b37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_selected_method():\n",
    "    method = run_selected_method.get()\n",
    "    if method not in visualization_functions:\n",
    "        messagebox.showerror(\"Error\", \"Please select a valid method from the dropdown.\")\n",
    "        return\n",
    "    # Call the corresponding function\n",
    "    visualization_functions[method]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ea01487",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Data Analytics Visualizer\")\n",
    "root.geometry(\"400x250\")\n",
    "# Define available visualization functions\n",
    "visualization_functions = {\n",
    "    \"Final Match Prediction\": visualize_final_prediction\n",
    "}\n",
    "\n",
    "# Function to run selected visualization method\n",
    "def run_selected_method():\n",
    "    selected = selected_method.get()\n",
    "    if selected in visualization_functions:\n",
    "        visualization_functions[selected]()\n",
    "    else:\n",
    "        tk.messagebox.showerror(\"Error\", \"Please select a valid visualization method.\")\n",
    "\n",
    "# Label for dropdown\n",
    "label = tk.Label(root, text=\"Select a Method to Visualize:\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Dropdown menu for selecting method\n",
    "selected_method = tk.StringVar()\n",
    "selected_method.set(\"Select a method\")\n",
    "dropdown = tk.OptionMenu(root, selected_method, *visualization_functions.keys())\n",
    "dropdown.pack(pady=10)\n",
    "\n",
    "# Button to run the selected method\n",
    "run_button = tk.Button(root, text=\"Visualize\", command=run_selected_method)\n",
    "run_button.pack(pady=20)\n",
    "\n",
    "# Start the tkinter main event loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
